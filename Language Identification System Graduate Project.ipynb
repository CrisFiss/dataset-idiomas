{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Daniel Vasilyonok</h2>\n",
    "<h3>Python for Data Science CSCI E - 29</h3>\n",
    "<h3>Natural Language Identification Machine Learning Pipeline - Graduate Project</h3>\n",
    "\n",
    "<p>\n",
    "In this project, I pulled text data from European Parliament Proceedings in 21 languages.\n",
    "Using Scikit-Learn, I transformed the raw text into a numerical feature matrix, and trained\n",
    "a Multinomial naive bayes probability model to classify input language with greater than 99% accuracy.\n",
    "</p>\n",
    "\n",
    "<p> \n",
    "Data Source: http://www.statmt.org/europarl/    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Required libraries\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# regular expression pattern used to filter out anything between < >\n",
    "# Non predictive speaker information in english is always in between those two symbols\n",
    "\n",
    "pattern = r'<(!?).*>'\n",
    "\n",
    "# Max length of language transcription\n",
    "# Ensure each language has similar amount of representation (Balanced Dataset)\n",
    "MAX_LENGTH_TRANSCRIPTION = 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map language index to natural language\n",
    "\n",
    "labels = { \n",
    "          1.0:'German',\n",
    "          2.0: 'English', \n",
    "          3.0: 'Spanish'\n",
    "          }\n",
    "\n",
    "# Map language to language code and file name\n",
    "\n",
    "language_codes_files = {\n",
    "    'German': ['de', '/ep-00-01-17.txt'], \n",
    "    'English': ['en', '/ep-00-01-17.txt'], \n",
    "    'Spanish': ['es', '/ep-00-01-17.txt']\n",
    "}\n",
    "\n",
    "# These languages need multiple files combined to get a transcription of length\n",
    "# >= MAX_LENGTH_TRANSCRIPTION\n",
    "limited_raw_text = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Helper Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def combine_text_files(language_code, language):\n",
    "   \n",
    "    '''\n",
    "    Goal: Certain languages do not have a single file of length >= MAX_LENGTH_TRANSCRIPTION\n",
    "          This function will combine these files for this sort of language into one language\n",
    "          transcription, and then write the transcription to a single file.\n",
    "    \n",
    "    @param: (string) language_code is the 2 character code of the language\n",
    "    @param: (string) language is the English name of the language         \n",
    "    '''    \n",
    "    \n",
    "    file_name_list = os.listdir('language_data/txt/' + language_code + '/')\n",
    "    language_transcription = ''\n",
    "    for file_name in file_name_list:\n",
    "        if(len(language_transcription) >= MAX_LENGTH_TRANSCRIPTION):\n",
    "            break;\n",
    "        path = os.getcwd() + '/language_data/txt/' + language_code + '/' + file_name\n",
    "        with open(path, 'r', errors='ignore') as f:\n",
    "            contents = f.read()\n",
    "            language_transcription += contents\n",
    "    \n",
    "    write_path = os.getcwd() + '/language_data/txt/' + language_code + '/' + language + '.txt'\n",
    "    with open(write_path, 'w', errors='ignore') as f:\n",
    "        f.write(language_transcription)\n",
    "\n",
    "def read_languages_data(path):\n",
    "    '''\n",
    "    Goal: Read language data from file path into a list containing one massive string\n",
    "    \n",
    "    @param path: (string) file path pointing to the raw natural language text\n",
    "                 Original file data source found here: http://www.statmt.org/europarl/\n",
    "    @return language_transcription: (list) language_transcription is a list of one string containing the whole text\n",
    "    '''\n",
    "    with open(path, 'r', errors='ignore') as f:\n",
    "        language_transcription = f.read()\n",
    "        language_transcription = language_transcription[:MAX_LENGTH_TRANSCRIPTION]\n",
    "    return language_transcription\n",
    "\n",
    "def clean_sentences(sentences):\n",
    "    '''\n",
    "    Goal: Filter out non predictive text about speaker using regular expression pattern\n",
    "    \n",
    "    @param sentences: (list) sentences is a list of strings, where each string is a sentence.\n",
    "                       Note: The raw language_transcription should be tokenized by sentence prior\n",
    "                       to being passed into this function.\n",
    "    '''\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentences[i] = re.sub(pattern,'',sentence)\n",
    "\n",
    "def combine_language_data(sentences, language_index):\n",
    "    '''\n",
    "    Goal: Transform list of string sentences into np.array, and stack horizontally with an np.array containing \n",
    "          the sentence's language_index, which maps to the sentence language. Essentially, apply label to data.\n",
    "    \n",
    "    @param sentences: (list) sentences is a list of strings that has had speaker information filtered out\n",
    "    @param language_index: (float) language_index is a float that maps to a specific language in the labels dictionary\n",
    "    @return language_data: (np.array) return an np.array of shape (# of sample sentences, 2 )\n",
    "    '''\n",
    "    sentences = np.array(sentences)\n",
    "    sentences = sentences.reshape(sentences.shape[0],1)\n",
    "    target = np.zeros((sentences.shape[0],1))\n",
    "    target += language_index\n",
    "    language_data = np.hstack((sentences, target))\n",
    "    return language_data\n",
    "\n",
    "def test_languages(X_test, true_values, predictions):\n",
    "    '''\n",
    "    Goal: Visualize the ~99% prediction accuracy by comparing,\n",
    "        1. natural language sentence\n",
    "        2. predicted natural language\n",
    "        3. true natural language\n",
    "    \n",
    "    @param X_test: (np.array) X_test is a np.array containing the unseen data from the test set\n",
    "    @param true_values: (np.array) true_values is a np.array containing the true language_index labels\n",
    "    @param predictions: (np.array) predictions is a np.array containing the predicted language_index labels\n",
    "    '''\n",
    "    \n",
    "    true_values = np.array(true_values)\n",
    "    \n",
    "    for i, sentence in enumerate(X_test):\n",
    "        prediction = float(predictions[i])\n",
    "        true_value = float(true_values[i])\n",
    "        print(\"Prediction: \" + str(labels[prediction]))\n",
    "        print(\"Actual Language: \" + str(labels[true_value]))\n",
    "        print(\"Input Sentence: \")\n",
    "        print(sentence)\n",
    "        print('\\n')\n",
    "\n",
    "def shuffle_rows(languages):\n",
    "    '''\n",
    "    Goal: Shuffle rows of 2D np.array with language data\n",
    "    \n",
    "    @param languages: un-mixed 2D np.array with language sentence features, and language_index labels\n",
    "    @return shuffled_languages: shuffled by row, 2D np.array \n",
    "    '''\n",
    "    \n",
    "    index = np.arange(0, len(languages))\n",
    "    np.random.shuffle(index)\n",
    "    shuffled_languages = languages[index,:]\n",
    "\n",
    "    return shuffled_languages\n",
    "    \n",
    "def preproccess_raw_data(file_paths):\n",
    "    '''\n",
    "    Goal: Run all data preprocessing helper functions\n",
    "    \n",
    "    @param file_paths: (list) file_paths is a list of string file paths. Each file path string\n",
    "                        points to a raw text file from the European Parliament Proceedings.\n",
    "    @return languages: (np.array) languages is a 2D np.array of shape (# sentences, 2)\n",
    "                        The first dimension has the a sentence, and the second dimension\n",
    "                        has the language_index label, that maps to the language.\n",
    "    '''\n",
    "    \n",
    "    # Combine transcriptions of subset languages into a single file to ensure\n",
    "    # each file will have len >= MAX_LENGTH_TRANSCRIPTION\n",
    "    language_codes_files_subset = dict( (key, language_codes_files[key] ) for key in limited_raw_text if key in language_codes_files )\n",
    "    for language in language_codes_files_subset.keys():\n",
    "        combine_text_files(language_codes_files_subset[language][0], language)\n",
    "    \n",
    "    # Read all raw text data from file paths\n",
    "    language_transcriptions = [ read_languages_data(path) for path in file_paths ]\n",
    "    \n",
    "    # tokenize each raw text string into a list of sentences\n",
    "    for i, language_transcription in enumerate(language_transcriptions):\n",
    "        language_transcriptions[i] = sent_tokenize(language_transcription)\n",
    "    \n",
    "    # Remove information about speakers using a regular expression pattern\n",
    "    for sentences in language_transcriptions:\n",
    "        clean_sentences(sentences)\n",
    "    \n",
    "    # Combine each language with its language_index\n",
    "    languages = [ combine_language_data(sentences,i+1) for i,sentences in enumerate(language_transcriptions) ]\n",
    "    \n",
    "    # Vertically stack all data into one 2D np.array\n",
    "    languages =  np.vstack((languages))\n",
    "    \n",
    "    # Shuffle languages by row\n",
    "    languages = shuffle_rows(languages)\n",
    "    \n",
    "    return languages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['There are bound to be otfactors, Rosing says.', '2.0'],\n",
       "       ['Se trata de un florecimiento de Lingulodinium polyedrum, un dinoflagelado que alcanzó un máximo de 550 mil células por litro en el muestreo del 17 de marzo.',\n",
       "        '3.0'],\n",
       "       ['Das macht sie zur idealin Probandin vor allem für übende angeZahnärzte.',\n",
       "        '1.0']], dtype='<U156')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all file paths\n",
    "\n",
    "file_paths = [ os.getcwd() + '/language_data/txt/' + language_codes_files[language][0] + language_codes_files[language][1] for language in language_codes_files ]\n",
    "\n",
    "# Preprocess all raw text into a form suitable for TfidfVectorizer\n",
    "languages = preproccess_raw_data(file_paths)\n",
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural language    False\n",
      "language index      False\n",
      "language            False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natural language</th>\n",
       "      <th>language index</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are bound to be otfactors, Rosing says.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Se trata de un florecimiento de Lingulodinium ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das macht sie zur idealin Probandin vor allem ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    natural language  language index language\n",
       "0      There are bound to be otfactors, Rosing says.             2.0  English\n",
       "1  Se trata de un florecimiento de Lingulodinium ...             3.0  Spanish\n",
       "2  Das macht sie zur idealin Probandin vor allem ...             1.0   German"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_languages = pd.DataFrame(languages)\n",
    "df_languages.columns = ['natural language', 'language index']\n",
    "df_languages['language index'] = df_languages['language index'].apply(float)\n",
    "df_languages['language'] = df_languages['language index'].map(labels)\n",
    "print(df_languages.isnull().any())\n",
    "display(df_languages.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_languages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into raw features and labels\n",
    "\n",
    "language_features = df_languages['natural language']\n",
    "language_targets = df_languages['language index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure Dataset is relativley balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 1, 2.0: 1, 3.0: 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(language_targets, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "# Train on 70% of data, Test on remaining 30%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(language_features, \n",
    "                                                    language_targets,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Machine Learning Pipeline</h2>\n",
    "\n",
    "<h3>Feature Engineering / Preprocessing</h3>\n",
    "<p>With the clean raw text sentences in hand, the natural languages are preprocessed using Scikit-Learn's\n",
    "TfidfVectorizer. Essentially, the raw text sentences are converted into a numerical feature matrix.\n",
    "Tfidf stands for Term frequency inverse document frequency, and the arguments I used are analyzer = 'char' and\n",
    "ngram_range = (1,3). Analyzer = 'char' tells the vectorizer to look at characters rather than words. \n",
    "ngram_range = (1,3) tells the vectorizer to assign tfidf scores to character sequences with max length of 3 characters\n",
    "and minimum length of 1 character. From doing some linguistic reasearch, I found that short character ngram sequences\n",
    "are predictive features of a natural languages.\n",
    "<br>\n",
    "<br>\n",
    "<b>How does TfidfVectorizer work in this situation?</b>\n",
    "<p>The count of each ngram is recorded and divided by the total ngrams in a sentence.\n",
    "This number is the tf (Term Frequency) in tfidf. Next, the term frequency is scaled down \n",
    "by being multiplied by how common it is in all sentences. This factor used by TfidfVectorizer in Scikit-Learn is\n",
    "1 + log(# sentences / # of sentences that contain the ngram). If an ngram is highly reccurent in many sentences, this\n",
    "inverse document frequency term (idf) gets smaller, and brings down the overall tfidf score. The idf term makes it so that words like the,of, or frequently used articles do not have too much weight in an ngram's score. The output of TfidfVectorizer is a numerical feature matrix that has maps the ngram index to its tfidf score. This can be passed into a Machine Learning model.</p>\n",
    "<h3>Naive Bayes Multinomial Model</h3>\n",
    "<p> In a Naive Bayes Multinomial Model, features are assumed to be generated from a multinomial distribution, rather than the slightly more simple Gaussian Naive Bayes model that assumes features are generated from a Gaussian distribution. The Multinomial Naive Bayes model is modeled with the best fit multinomial distribution. The model\n",
    "works by computing a large table of probabilities with the given data. Using the Liklihood -- P(feature|Label), the Prior-- P(Label), and the Marginal Liklihood-- P(feature), the model takes advatage of Baye's Theorm to compute \n",
    "P(Label|feature). The P(Label|feature) with the highest probability gets predicted as the correct language.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make Machine Learning Pipeline with TfidfVectorizer and MultinomialNB\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='char', ngram_range=(1,3))\n",
    "model = MultinomialNB()\n",
    "text_clf = Pipeline([('tfidf', tfidf_vect),\n",
    "                    ('clf', model),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train model with pipeline classifier\n",
    "\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on unseen test data with trained classifier\n",
    "\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Measure accuracy\n",
    "\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cross Validated Accuracy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    796\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m                 \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-9e9140179066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# alternate train and test set through cross validation to yield a more trustworthy accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean cross-validation accuracy: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    806\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m                 \u001b[0mislice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    229\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m    230\u001b[0m     scores = parallel(\n\u001b[1;32m--> 231\u001b[1;33m         delayed(_fit_and_score)(\n\u001b[0m\u001b[0;32m    232\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    331\u001b[0m                 (\"Cannot have number of splits n_splits={0} greater\"\n\u001b[0;32m    332\u001b[0m                  \" than the number of samples: n_samples={1}.\")\n\u001b[1;32m--> 333\u001b[1;33m                 .format(self.n_splits, n_samples))\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3."
     ]
    }
   ],
   "source": [
    "\n",
    "# alternate train and test set through cross validation to yield a more trustworthy accuracy\n",
    "\n",
    "scores = cross_val_score(text_clf, language_features, language_targets, cv=5)\n",
    "print(\"Mean cross-validation accuracy: \" + str(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classification Report</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names=labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_names = list(language_codes_files.keys())\n",
    "plt.figure(figsize=(32, 32))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "ax = sns.heatmap(cm, annot = True, fmt = \"d\")\n",
    "\n",
    "ax.set_xlabel('Predicted Language')\n",
    "ax.set_ylabel('Actual Language')\n",
    "ax.set_title('Language Identification Confusion Matrix')\n",
    "ax.set_xticklabels(labels.values())\n",
    "ax.set_yticklabels(labels.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 21x21 Confusion Matrix</h1>\n",
    "\n",
    "<p> \n",
    "The well defined diagonal is a visual representation \n",
    "of the good performance of this language classifier.\n",
    "Although this model performs quite well, there are a few misclassifications.\n",
    "The confusion matrix gives insight into where the model makes errors.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Performance\n",
    "\n",
    "test_languages(X_test, y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter data\n",
    "\n",
    "pred = text_clf.predict(['I\\'ve #got a feeling! 👌'])\n",
    "\n",
    "labels[float(pred[0])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
